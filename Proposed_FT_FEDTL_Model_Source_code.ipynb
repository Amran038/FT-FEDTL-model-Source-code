{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bLdeJUcQSzn2"
      },
      "outputs": [],
      "source": [
        "# import all necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten,GlobalAveragePooling2D\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data directory path for display or show the image from the directory\n",
        "\n",
        "data_dir = ('image directiory or path') # traininvg or validation image path\n",
        "categories = ['NT', 'SBT', 'SMT', 'TBT', 'TMT', 'SBSMT']# Put your class names\n ",
        "n_classes = len(categories)\n",
        "for i in categories:\n",
        "    path = os.path.join(data_dir, i)\n",
        "    for img in os.listdir(path):\n",
        "        img_array = cv2.imread(os.path.join(path,img))\n",
        "\n",
        "\n",
        "# Image Visualize\n",
        "plt.imshow(img_array);\n",
        "# The image shape.\n",
        "img_array.shape\n",
        "\n",
        "# Define Image shape\n",
        "img_height = 299\n",
        "img_width = 299\n",
        "n_classes = 6 # Number of class for"
      ],
      "metadata": {
        "id": "VNc6cKpNS5fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Data generator for training and Validation\n",
        "\n",
        "image_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                    featurewise_center=False,\n",
        "                                    samplewise_center=False,\n",
        "                                    featurewise_std_normalization=False,\n",
        "                                    samplewise_std_normalization=False,\n",
        "                                    zca_whitening=False,\n",
        "                                    rotation_range=0,\n",
        "                                    zoom_range = 0,\n",
        "                                    width_shift_range=0,\n",
        "                                    height_shift_range=0,\n",
        "                                    horizontal_flip=True,\n",
        "                                    vertical_flip=False,\n",
        "                                    validation_split=0.0)\n",
        "\n",
        "test_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                    validation_split=0.0)\n",
        "\n",
        "train = image_generator.flow_from_directory('training image path', target_size=(img_height, img_width),\n",
        "                                              batch_size=16, class_mode= \"categorical\", color_mode='rgb', subset='training', interpolation='bicubic') # This is only when you have a separate directory for 80% training image\n",
        "\n",
        "valid = test_generator.flow_from_directory('Validation Image path', target_size=(img_height, img_width),\n",
        "                                              batch_size=16, class_mode= \"categorical\", color_mode='rgb', subset='training', interpolation='bicubic') # This is only when you have a separate directory for 20% validation image\n",
        "\n",
        "# you can also use the following codes for if you have all image dataset in a directory and the code automatically split the whole dataset into training and validation\n",
        "\n",
        "#dir_path=\"image dataset directory path\"\n",
        "#train_data = image_generator.flow_from_directory(dir_path, target_size=(img_height, img_width), batch_size=16, validation_split=0.2,class_mode= \"categorical\", color_mode='rgb', subset='training', interpolation='bicubic') # Split the dataset into 80% training dataset\n",
        "\n",
        "#valid_data = test_generator.flow_from_directory(dir_path, target_size=(img_height, img_width), batch_size=16, validation_split=0.2, class_mode= \"categorical\", color_mode='rgb', subset='validation', interpolation='bicubic') # Split the dataset into 20% validation dataset\n",
        "\n",
        "# Please use the above varibales in the folowing line of codes when you need #\n"
      ],
      "metadata": {
        "id": "ibVpPaRGgM5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Confusion Matrix\n",
        "\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "\n",
        "    #This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`.\n",
        "\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], '.2f'),\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"black\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')"
      ],
      "metadata": {
        "id": "hkdHsauug_Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Accuracy and Loss Curve\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#plot loss and accuracy helper function\n",
        "def plot_accuracy(history):\n",
        "    plt.plot(history.history['categorical_accuracy'])\n",
        "    plt.plot(history.history['val_categorical_accuracy'])\n",
        "    #plt.title('model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "def plot_loss(history):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    #plt.title('model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rUuEP3TjhbVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Proposed FT-DTL Model creation\n",
        "\n",
        "Base_model= tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# The last 15 layers fine tune\n",
        "for layer in Base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Fine-tuned additional layers to base model\n",
        "x = Base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(units=512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(units=512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output  = Dense(units=n_classes, activation='softmax')(x)\n",
        "proposed_FT_FEDTL = Model(Base_model.input, output)\n",
        "proposed_FT_FEDTL.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "#proposed_FT_FEDTL.summary() # optional"
      ],
      "metadata": {
        "id": "SZpUrguWkI0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compile\n",
        "proposed_FT_FEDTL.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=['categorical_accuracy'])"
      ],
      "metadata": {
        "id": "58gVqMHAmVeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up fine-tuned hyperparameters and start the training of the model\n",
        "\n",
        "model_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 40, verbose = 1)\n",
        "model_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 40, verbose = 1)\n",
        "model_mcp = ModelCheckpoint(filepath = 'inp_model_weights.h5', monitor = 'val_categorical_accuracy',\n",
        "                      save_best_only = True, verbose = 1)\n",
        "history = proposed_FT_FEDTL.fit(train, steps_per_epoch=1050//16, epochs=100, validation_data=valid, validation_steps= 200//16, callbacks=[model_es, model_rlr, model_mcp])"
      ],
      "metadata": {
        "id": "zq2cjv2xmV6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call Accuracy and Loss functions to print the graphs\n",
        "\n",
        "plot_accuracy(history)\n",
        "plot_loss(history)"
      ],
      "metadata": {
        "id": "N8O4Dz0Spy1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the samples prediction\n",
        "\n",
        "test_samples = test_generator.flow_from_directory('testing image path', target_size=(img_height, img_width),\n",
        "                                              batch_size=16, class_mode= \"categorical\", color_mode='rgb', interpolation='bicubic')\n",
        "test_imgs, test_labels = next(test_samples)\n",
        "rounded_labels = np.argmax(test_labels, axis=-1)\n",
        "predictions = proposed_FT_FEDTL.predict_generator(test_samples, steps=1, verbose=0)\n",
        "rounded_prediction = np.argmax(predictions, axis=-1)"
      ],
      "metadata": {
        "id": "2zqxgMx8qT8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call Confusion matrix function to plot the matrix\n",
        "cm = confusion_matrix(y_true=rounded_labels, y_pred=rounded_prediction)\n",
        "# plot confusion matrix\n",
        "plot_confusion_matrix(cm=cm, classes = categories, title='confusion_matrix')"
      ],
      "metadata": {
        "id": "Hh8uPojSq3Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Classification  report\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(rounded_labels,rounded_prediction))"
      ],
      "metadata": {
        "id": "Ns4oCmXYrSxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Proposed Model Evaluate\n",
        "\n",
        "for imgbatch, labelbatch in test_samples:\n",
        "  print(\"Batch Size: \", imgbatch.shape)\n",
        "  print(\"Label Batch Size: \", labelbatch.shape)\n",
        "\n",
        "test_loss, test_accuracy=proposed_FT_FEDTL.evaluate(test_samples)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Test Loss:\", test_loss)"
      ],
      "metadata": {
        "id": "8IIz7r2zsZga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image sample testing result\n",
        "image=cv2.imread(str(result[0]))\n",
        "image_resize=cv2.resize(image,(img_height,img_width ))\n",
        "image=np.expand_dims(image_resize, axis=0)\n",
        "print(image.shape)\n",
        "prediction=proposed_FT_FEDTL.predict(image)\n",
        "print(prediction)\n",
        "outputclass=categories[np.argmax(prediction)]\n",
        "print(\"The predicted class Name is :\", outputclass)"
      ],
      "metadata": {
        "id": "2kWn_2sCwZjY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
